{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon, Point\n",
    "from descartes import PolygonPatch\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "pd.set_option('io.hdf.default_format', 'table')\n",
    "import numpy as np\n",
    "from pyproj import Proj\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import h5py\n",
    "import bcolz\n",
    "import random\n",
    "sys.path.append('../pyx')\n",
    "sys.path.append('../py')\n",
    "import subprocess\n",
    "os.chdir('../pyx')\n",
    "subprocess.call(['python', 'setup_cmodels.py', 'build_ext', '-if'])\n",
    "os.chdir('../ipynb')\n",
    "import cmodels as cmod\n",
    "import models as mod\n",
    "from delineate import Delineate\n",
    "import calibration as cal\n",
    "from multiprocessing import Pool\n",
    "from scipy import optimize\n",
    "from numba import jit\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the basin partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('../data/amazon/partition.pkl', 'rb') as f:\n",
    "        ws = pickle.load(f)\n",
    "except:\n",
    "    d = Delineate()\n",
    "    d.delineate(-1.914, -53.84)\n",
    "    with open('../data/amazon/partition.pkl', 'wb') as f:\n",
    "        pickle.dump(d.watersheds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ws = DataFrame()\n",
    "df_ws['odr'] = [str(i['order']).replace('[', '').replace(']', '').replace(' ', '') for i in ws]\n",
    "df_ws['out'] = [i['outlet'] for i in ws]\n",
    "#df_ws['geo'] = [i['geometry'] for i in ws]\n",
    "df_ws['mask'] = [i['mask'] for i in ws]\n",
    "df_ws['latlon'] = [i['latlon'] for i in ws]\n",
    "if not True:\n",
    "    df_ws['geo'] = None\n",
    "    for i, j in enumerate(ws):\n",
    "        this_ws = [j['geometry']]\n",
    "        done = False\n",
    "        ws_list = []\n",
    "        ws_i = 0\n",
    "        while not done:\n",
    "            if type(this_ws[ws_i]) == Polygon:\n",
    "                if this_ws[ws_i].is_valid:\n",
    "                    ws_list.append(this_ws[ws_i])\n",
    "                    ws_i += 1\n",
    "                else:\n",
    "                    this_ws[ws_i] = this_ws[ws_i].buffer(0)\n",
    "            else: # expand multi-polygon\n",
    "                this_ws = this_ws[:ws_i] + [k for k in this_ws[ws_i]] + this_ws[ws_i + 1:]\n",
    "            if ws_i == len(this_ws):\n",
    "                done = True\n",
    "        df_ws.loc[i, 'geo'] = ws_list\n",
    "df_ws = df_ws.set_index('odr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the basin partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat0, lat1, lon0, lon1 = -21, 6, -80, -52 # bounding box in degrees\n",
    "gpm_res = 0.1 # IMERG resolution in degrees\n",
    "pet_res = 1 / 120 # PET resolution in degrees (0.008333)\n",
    "acc_res = 1 / 120 # flow accumulation resolution in degrees (0.008333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_ws(odrs):\n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    m = Basemap(projection = 'cyl', resolution = 'l', area_thresh = 10000, llcrnrlat = lat0, urcrnrlat = lat1, llcrnrlon = lon0, urcrnrlon = lon1)\n",
    "    m.drawcoastlines()\n",
    "    m.drawcountries()\n",
    "\n",
    "    this_mask = np.zeros((int((lat1 - lat0) / acc_res), int((lon1 - lon0) / acc_res)), dtype = 'uint8')\n",
    "    odr_max = 0\n",
    "    for i, this_odr in enumerate(odrs):\n",
    "        #this_ws = this_row[1]['geo']\n",
    "        this_out = df_ws.loc[this_odr, 'out']\n",
    "        mask = df_ws.loc[this_odr, 'mask']\n",
    "        latlon = df_ws.loc[this_odr,  'latlon']\n",
    "        if not True:\n",
    "            if i == 0:\n",
    "                allWs = this_ws[0]\n",
    "            for pol in this_ws:\n",
    "                allWs = allWs.union(pol)\n",
    "        this_len = len(this_odr)\n",
    "        if this_len > odr_max:\n",
    "            odr_max = this_len\n",
    "        #if type(this_ws) == Polygon:\n",
    "        #    ws_list = [this_ws]\n",
    "        #else:\n",
    "        #    ws_list = this_ws\n",
    "        y0 = int(round((lat1 - latlon[0]) / acc_res))\n",
    "        y1 = y0 + mask.shape[0]\n",
    "        x0 = int(round((latlon[1] - lon0) / acc_res))\n",
    "        x1 = x0 + mask.shape[1]\n",
    "        this_mask[y0:y1, x0:x1] = this_mask[y0:y1, x0:x1] + mask * int(np.random.uniform(1, 255))\n",
    "        if not True:\n",
    "            for pol in ws_list:\n",
    "                polygon = PolygonPatch(pol)\n",
    "                polygon.set_facecolor('white')\n",
    "                #polygon.set_edgecolor('white')\n",
    "                #polygon.set_linewidth(0.01)\n",
    "                ax.add_patch(polygon)\n",
    "        #ax.scatter(this_out[1], this_out[0], color = 'black', alpha = .3, zorder = 10)\n",
    "\n",
    "    this_mask = np.where(this_mask == 0, np.nan, this_mask)\n",
    "    m.imshow(this_mask, origin = 'upper', interpolation = 'nearest', zorder = 10, alpha = 1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute every subbasin's mask\n",
    "It is a np.array in the native IMERG resolution, so that masking the precipitation over the subbasin is just a multiplication. The boundary pixels are a fraction of the precipitation pixels, according to the area covered by the subbasin inside each pixel.\n",
    "\n",
    "Keep in mind that this doesn't work (yet) for subbasins which have a hole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_ws = pd.read_pickle('../data/amazon/amazon.pkl')\n",
    "except:\n",
    "    df_ws['gpm_mask'] = None\n",
    "    df_ws['pet_mask'] = None\n",
    "    df_ws['acc_mask'] = None\n",
    "    df_ws['gpm_view'] = None\n",
    "    df_ws['pet_view'] = None\n",
    "    with rasterio.drivers():\n",
    "        with rasterio.open('../data/amazon/sa_acc_30s/sa_acc_30s/w001001.adf') as src:\n",
    "            data, = src.read()\n",
    "            acc_aff = src.affine\n",
    "    \n",
    "    x0, y0 = [int(round(i)) for i in ~acc_aff * (lon0, lat1)]\n",
    "    x1, y1 = [int(round(i)) for i in ~acc_aff * (lon1, lat0)]\n",
    "    acc = data[y0:y1, x0:x1]\n",
    "    for ws_i in tqdm(range(len(df_ws))):\n",
    "        this_odr = df_ws.index[ws_i]\n",
    "        this_mask = df_ws.iloc[ws_i]['mask']\n",
    "\n",
    "        # subbasin's bounding box:\n",
    "        lt1, ln0 = df_ws.iloc[ws_i]['latlon']\n",
    "        lt0 = lt1 - acc_res * this_mask.shape[0]\n",
    "        ln1 = ln0 + acc_res * this_mask.shape[1]\n",
    "            \n",
    "        gpm_mask = np.zeros((int(round((lat1 - lat0) / gpm_res)), int(round((lon1 - lon0) / gpm_res))))\n",
    "        pet_mask = np.zeros((int(round((lat1 - lat0) / pet_res)), int(round((lon1 - lon0) / pet_res))))\n",
    "        acc_mask = np.zeros_like(this_mask, dtype = 'int32')\n",
    "        for res in set([gpm_res, pet_res]):\n",
    "            x0 = int(np.floor((ln0 - lon0) / res))\n",
    "            x1 = int(np.ceil((ln1 - lon0) / res))\n",
    "            y0 = int(np.floor((lat1 - lt1) / res))\n",
    "            y1 = int(np.ceil((lat1 - lt0) / res))\n",
    "            if res == gpm_res:\n",
    "                df_ws.loc[this_odr, 'gpm_view'] = [x0, x1, y0, y1]\n",
    "            if res == pet_res:\n",
    "                df_ws.loc[this_odr, 'pet_view'] = [x0, x1, y0, y1]\n",
    "            for y in range(y0, y1):\n",
    "                for x in range(x0, x1):\n",
    "                    yy0 = int(round((lt1 - (lat1 - y * res)) / acc_res))\n",
    "                    yy1 = int(round((lt1 - (lat1 - (y + 1) * res)) / acc_res))\n",
    "                    xx0 = int(round(((lon0 + x * res) - ln0) / acc_res))\n",
    "                    xx1 = int(round(((lon0 + (x + 1) * res) - ln0) / acc_res))\n",
    "                    xxyy = [xx0, xx1, yy0, yy1]\n",
    "                    xxyy[0] = np.max([0, xxyy[0]])\n",
    "                    xxyy[1] = np.min([this_mask.shape[1], xxyy[1]])\n",
    "                    xxyy[2] = np.max([0, xxyy[2]])\n",
    "                    xxyy[3] = np.min([this_mask.shape[0], xxyy[3]])\n",
    "                    xx0, xx1, yy0, yy1 = xxyy\n",
    "                    res_ratio = int(round(res / acc_res))\n",
    "                    if res == gpm_res:\n",
    "                        gpm_mask[y, x] = float(np.sum(this_mask[yy0:yy1, xx0:xx1])) / (res_ratio * res_ratio)\n",
    "                    if res == pet_res:\n",
    "                        pet_mask[y, x] = float(np.sum(this_mask[yy0:yy1, xx0:xx1])) / (res_ratio * res_ratio)\n",
    "\n",
    "        x0, x1, y0, y1 = df_ws.loc[this_odr, 'gpm_view']\n",
    "        df_ws.loc[this_odr, 'gpm_mask'] = gpm_mask[y0:y1, x0:x1].copy()\n",
    "        x0, x1, y0, y1 = df_ws.loc[this_odr, 'pet_view']\n",
    "        df_ws.loc[this_odr, 'pet_mask'] = pet_mask[y0:y1, x0:x1].copy()\n",
    "        x0 = int(round((ln0 - lon0) / acc_res))\n",
    "        x1 = int(round((ln1 - lon0) / acc_res))\n",
    "        y0 = int(round((lat1 - lt1) / acc_res))\n",
    "        y1 = int(round((lat1 - lt0) / acc_res))\n",
    "        df_ws.loc[this_odr, 'acc_view'] = [x0, x1, y0, y1]\n",
    "        df_ws.loc[this_odr, 'acc_mask'] = acc[y0:y1, x0:x1] * this_mask\n",
    "\n",
    "        if not True:\n",
    "            this_ws = df_ws.iloc[ws_i]['geo']\n",
    "            plt.close('all')\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            m = Basemap(projection = 'cyl', resolution = 'l', area_thresh = 10000, llcrnrlat = lat0, urcrnrlat = lat1, llcrnrlon = lon0, urcrnrlon = lon1)\n",
    "            m.drawcoastlines()\n",
    "            m.drawcountries()\n",
    "            if type(this_ws) == Polygon:\n",
    "                ws_list = [this_ws]\n",
    "            else:\n",
    "                ws_list = this_ws\n",
    "            for pol in ws_list:\n",
    "                polygon = PolygonPatch(pol, zorder = 1)\n",
    "                polygon.set_facecolor('white')\n",
    "                ax.add_patch(polygon)\n",
    "            m.imshow(np.where(gpm_mask == 0, np.nan, gpm_mask), cmap = 'binary', interpolation = 'nearest', origin = 'upper', alpha = 0.5, zorder = 10)\n",
    "            plt.show()\n",
    "\n",
    "    df_ws.to_pickle('../data/amazon/amazon.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the sum of all subbasin masks is the whole basin. It should be 1 inside (of course not at the edge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "mask = np.zeros((int((lat1 - lat0) / gpm_res), int((lon1 - lon0) / gpm_res)))\n",
    "for this_row in df_ws.iterrows():\n",
    "    this_mask = this_row[1]['gpm_mask']\n",
    "    x0, x1, y0, y1 = this_row[1]['gpm_view']\n",
    "    mask[y0:y1, x0:x1] = mask[y0:y1, x0:x1] + this_mask\n",
    "plt.imshow(mask, interpolation = 'nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the precipitation over each subbasin\n",
    "We take the subset of the precipitation array that corresponds to the subbasin array, and just multiply them and take the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_imerg = pd.read_pickle('../data/amazon/imerg.pkl')\n",
    "except:\n",
    "    rootDir = '/media/disk/data/imerg/late/'\n",
    "    if os.path.exists(rootDir):\n",
    "        dates = []\n",
    "        files = []\n",
    "        for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "            for fname in fileList:\n",
    "                if fname.endswith('RT-H5'):\n",
    "                    year = int(fname[23:27])\n",
    "                    month = int(fname[27:29])\n",
    "                    day = int(fname[29:31])\n",
    "                    hour = int(fname[33:35])\n",
    "                    minu = int(fname[35:37])\n",
    "                    dates.append(datetime(year, month, day, hour, minu))\n",
    "                    files.append(dirName + '/' + fname)\n",
    "        df_imerg = DataFrame(data = files, index = dates, columns = ['file']).sort_index()\n",
    "        # check whether there are missing/duplicate dates:\n",
    "        date_range = pd.date_range(df_imerg.index[0], df_imerg.index[-1], freq = '30min')\n",
    "        for this_date in date_range:\n",
    "            if this_date not in df_imerg.index:\n",
    "                print(str(this_date) + ' not found')\n",
    "            elif len(df_imerg.loc[this_date]) > 1:\n",
    "                print(str(this_date) + ' appears multiple times')\n",
    "    df_imerg.to_pickle('../data/amazon/imerg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the mean precipitation over each subbasin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ca_gpm = bcolz.open(rootdir = '../data/amazon/ca_gpm', mode = 'r')\n",
    "except:\n",
    "    res = gpm_res\n",
    "    x0 = int((lon0 - (-180)) / res)\n",
    "    x1 = int((lon1 - (-180)) / res)\n",
    "    y0 = int((90 - lat1) / res)\n",
    "    y1 = int((90 - lat0) / res)\n",
    "\n",
    "    # in order to minimize disk access, we get the precipitations of all subbasins\n",
    "    # for a precipitation file (i.e. a date), then the next date, etc.\n",
    "    ca_gpm = bcolz.zeros((0, len(df_ws)), dtype = 'f8', rootdir = '../tmp/ca_gpm', mode = 'w')\n",
    "    for this_date in tqdm(df_imerg.index):\n",
    "        data_loaded = False\n",
    "        df = np.empty(len(df_ws.index))\n",
    "        for odr_i, this_odr in enumerate(df_ws.index):\n",
    "            this_mask = df_ws.loc[this_odr, 'gpm_mask']\n",
    "            if not data_loaded:\n",
    "                f = h5py.File(df_imerg.loc[this_date, 'file'], 'r')\n",
    "                data = np.array(f['Grid/precipitationCal']).transpose()[::-1][y0:y1, x0:x1]\n",
    "                data = np.clip(data, 0, np.inf)\n",
    "                f.close()\n",
    "                data_loaded = True\n",
    "                np.save('../data/amazon/shrink/p_' + str(this_date).replace(' ', '_'), data)\n",
    "            xx0, xx1, yy0, yy1 = df_ws.loc[this_odr, 'gpm_view']\n",
    "            p = np.sum(data[yy0:yy1, xx0:xx1] * this_mask) / np.sum(this_mask)\n",
    "            df[odr_i] = p\n",
    "        ca_gpm.append(df)\n",
    "    ca_gpm.flush()\n",
    "    # transpose carray:\n",
    "    ca_gpm2 = bcolz.zeros((0, ca_gpm.shape[0]), dtype = 'f4', rootdir = '../data/amazon/ca_gpm', mode = 'w')\n",
    "    for i in tqdm(range(ca_gpm.shape[1])):\n",
    "        ca_gpm2.append(ca_gpm[:, i])\n",
    "    ca_gpm2.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_odr_startswith(odrs, odr):\n",
    "    odr_list = []\n",
    "    for this_odr in odrs:\n",
    "        if this_odr.startswith(odr):\n",
    "            odr_list.append(this_odr)\n",
    "    return odr_list\n",
    "\n",
    "def substract_odr(odr1, odr2):\n",
    "    odr = []\n",
    "    for this_odr in odr1:\n",
    "        if this_odr not in odr2:\n",
    "            odr.append(this_odr)\n",
    "    return odr\n",
    "\n",
    "def intersect_odr(odr1, odr2):\n",
    "    odr = []\n",
    "    for this_odr in odr1:\n",
    "        if this_odr in odr2:\n",
    "            odr.append(this_odr)\n",
    "    return odr\n",
    "\n",
    "def get_p_imerg(df_ws, df_imerg, ca_gpm, odr):\n",
    "    first_time = True\n",
    "    pix_sum = 0.\n",
    "    for odr_i, this_odr in enumerate(df_ws.index):\n",
    "        if this_odr in odr:\n",
    "            this_mask = df_ws.loc[this_odr, 'mask']\n",
    "            this_p = ca_gpm[odr_i] * np.sum(this_mask)\n",
    "            pix_sum += np.sum(this_mask)\n",
    "            if first_time:\n",
    "                first_time = False\n",
    "                p_imerg = this_p\n",
    "            else:\n",
    "                p_imerg = p_imerg + this_p\n",
    "    p_imerg = Series(data = p_imerg / pix_sum, index = df_imerg.index)\n",
    "    if p_imerg.index[0].to_datetime().minute != 0:\n",
    "        p_imerg = p_imerg.iloc[1:]\n",
    "    p_imerg = p_imerg.reindex(pd.date_range(p_imerg.index[0], p_imerg.index[-1], freq = '30min'))\n",
    "    p_imerg = p_imerg.interpolate()\n",
    "    p_imerg = pd.rolling_mean(p_imerg, window = 3, min_periods = 3, center = True)\n",
    "    p_imerg = p_imerg.iloc[1::2].dropna()\n",
    "    p_imerg.index = (p_imerg.index - timedelta(minutes = 30)).tz_localize('UTC')\n",
    "    return p_imerg\n",
    "\n",
    "def get_pet(df_ws, df_imerg, df_pet, odr):\n",
    "    pix_sum = 0.\n",
    "    months = np.array([this_date.month for this_date in df_imerg.index], dtype = 'uint8')\n",
    "    this_pet = np.empty(len(df_imerg.index))\n",
    "    pet = np.zeros_like(this_pet)\n",
    "    for this_odr in df_ws.index:\n",
    "        if this_odr in odr:\n",
    "            this_mask = df_ws.loc[this_odr, 'mask']\n",
    "            for i in range(1, 12 + 1):\n",
    "                this_pet[np.where(months == i)] = df_pet.loc[i, this_odr]\n",
    "            this_pet = this_pet * np.sum(this_mask)\n",
    "            pix_sum += np.sum(this_mask)\n",
    "            pet = pet + this_pet\n",
    "    pet = Series(data = pet / pix_sum, index = df_imerg.index)\n",
    "    if pet.index[0].to_datetime().minute != 0:\n",
    "        pet = pet.iloc[1:]\n",
    "    pet = pet.reindex(pd.date_range(pet.index[0], pet.index[-1], freq = '30min'))\n",
    "    pet = pet.interpolate()\n",
    "    pet = pd.rolling_mean(pet, window = 3, min_periods = 3, center = True)\n",
    "    pet = pet.iloc[1::2].dropna()\n",
    "    pet.index = (pet.index - timedelta(minutes = 30)).tz_localize('UTC')\n",
    "    return pet\n",
    "\n",
    "def get_area(df_ws, odr):\n",
    "    area = 0.\n",
    "    for this_odr in odr:\n",
    "        area += np.sum(df_ws.loc[this_odr, 'mask'])\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_pet = pd.read_pickle('../data/amazon/pet.pkl')\n",
    "except:\n",
    "    res = pet_res\n",
    "    x0 = int((lon0 - (-180)) / res)\n",
    "    x1 = int((lon1 - (-180)) / res)\n",
    "    y0 = int((90 - lat1) / res)\n",
    "    y1 = int((90 - lat0) / res)\n",
    "\n",
    "    df_pet = DataFrame(columns = df_ws.index, index = range(1, 12 + 1))\n",
    "    for this_month in tqdm(range(1, 12 + 1)):\n",
    "        try:\n",
    "            del data\n",
    "        except:\n",
    "            pass\n",
    "        with rasterio.drivers():\n",
    "            with rasterio.open('../data/amazon/PET_he_monthly/pet_he_' + str(this_month) + '/w001001.adf') as src:\n",
    "                data, = src.read()\n",
    "        yy0, yy1 = int(round((lat1 - src.affine[5]) / src.affine[4])), int(round((lat0 - src.affine[5]) / src.affine[4]))\n",
    "        xx0, xx1 = int(round((lon0 - src.affine[2]) / src.affine[0])), int(round((lon1 - src.affine[2]) / src.affine[0]))\n",
    "        data = data[y0:y1, x0:x1]\n",
    "        np.clip(data, 0, np.inf, out = data)\n",
    "        for this_odr in df_ws.index:\n",
    "            this_mask = df_ws.loc[this_odr, 'pet_mask']\n",
    "            xx0, xx1, yy0, yy1 = df_ws.loc[this_odr, 'pet_view']\n",
    "            pet = np.sum(data[yy0:yy1, xx0:xx1] * this_mask) / np.sum(this_mask) / 30 / 24 # in mm/h\n",
    "            df_pet.loc[this_month, this_odr] = pet\n",
    "    df_pet.to_pickle('../data/amazon/pet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    peq = pd.read_pickle('../data/amazon/peq.pkl')\n",
    "except:\n",
    "    df = pd.read_csv('../data/amazon/R_amz_amz_ja2_0215_01.txt', skiprows = 20, sep = ';', header = None, names = ['col0', 'date', 'time', 'height', 'col4', 'col5', 'col6'])\n",
    "    df = df[['date', 'time', 'height']]\n",
    "    dates = []\n",
    "    for i in df.index:\n",
    "        this_date = df.loc[i, 'date'].replace(' ', '')\n",
    "        this_time = df.loc[i, 'time'].replace(' ', '')\n",
    "        dates.append(datetime(year = int(this_date[:4]), month = int(this_date[5:7]), day = int(this_date[8:]), hour = int(this_time[:2])))\n",
    "    df.index = dates\n",
    "    df = df['height']\n",
    "    df = df.reindex(pd.date_range(df.index[0], df.index[-1], freq = '1H'))\n",
    "    df.index = df.index.tz_localize('UTC')\n",
    "    #df_q = df.interpolate()\n",
    "    df_q = df\n",
    "\n",
    "    p_imerg = get_p_imerg(df_ws, df_imerg, ca_gpm, get_odr_startswith(df_ws.index, '0'))\n",
    "    pet = get_pet(df_ws, df_imerg, df_pet, get_odr_startswith(df_ws.index, '0'))\n",
    "    peq = DataFrame()\n",
    "    peq['p'] = p_imerg\n",
    "    peq['e'] = pet\n",
    "    peq['q'] = df_q\n",
    "\n",
    "    peq.to_pickle('../data/amazon/peq.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_cal(x_ranges):\n",
    "    df_cal = DataFrame()\n",
    "    x_sample_nb = 100\n",
    "    for x_i in range(4):\n",
    "        param = 'x' + str(x_i + 1)\n",
    "        df_cal[param + '_range'] = np.linspace(x_ranges[x_i][0], x_ranges[x_i][1], x_sample_nb)\n",
    "        df_cal[param + '_score'] = -np.inf\n",
    "    return df_cal\n",
    "\n",
    "@jit\n",
    "def dist_map(dst, src):\n",
    "    ret = np.empty_like(dst)\n",
    "    dist0 = np.empty_like(src)\n",
    "    dist1 = np.empty_like(dst)\n",
    "    nb = 0\n",
    "    for i in range(len(src)):\n",
    "        if (not np.isnan(src[i])) and (not np.isnan(dst[i])):\n",
    "            dist0[nb] = src[i]\n",
    "            dist1[nb] = dst[i]\n",
    "            nb += 1\n",
    "    dist0[:nb].sort()\n",
    "    dist1[:nb].sort()\n",
    "    for i in range(len(dst)):\n",
    "        if np.isnan(dst[i]):\n",
    "            ret[i] = np.nan\n",
    "        else:\n",
    "            j = 0\n",
    "            done = False\n",
    "            while not done:\n",
    "                if dst[i] == dist1[j]:\n",
    "                    done = True\n",
    "                else:\n",
    "                    j += 1\n",
    "            ret[i] = dist0[j]\n",
    "    return ret\n",
    "\n",
    "def single_cal(peq, df_cal):\n",
    "    x_sample_nb = len(df_cal)\n",
    "    x = np.empty(4)\n",
    "    iter_nb = x_sample_nb * 20\n",
    "    for i in range(iter_nb):\n",
    "        for x_i in range(4):\n",
    "            this_range = 'x' + str(x_i + 1) + '_range'\n",
    "            x[x_i] = random.uniform(df_cal.loc[0, this_range], df_cal.loc[x_sample_nb - 1, this_range])\n",
    "        q_mod = mod.gr4h(x)\n",
    "        # warm-up:\n",
    "        q_mod.run(peq)\n",
    "        q_mod.run(peq)\n",
    "        q_mod.run(peq)\n",
    "        q_sim = q_mod.run(peq)\n",
    "        q_obs = dist_map(peq['q'].values, q_sim.values)\n",
    "\n",
    "        warmup = 24 * 30\n",
    "        score = cal.nse(q_obs[warmup:], q_sim.values[warmup:])\n",
    "        for x_i in range(4):\n",
    "            done = False\n",
    "            k = 1\n",
    "            while not done:\n",
    "                if x[x_i] <= df_cal.loc[k, 'x' + str(x_i + 1) + '_range']:\n",
    "                    done = True\n",
    "                else:\n",
    "                    k += 1\n",
    "            this_score = 'x' + str(x_i + 1) + '_score'\n",
    "            if score > df_cal.loc[k, this_score]:\n",
    "                df_cal.loc[k, this_score] = score\n",
    "    return df_cal\n",
    "\n",
    "def dual_cal(peq, df_cal, df_x, proc_nb):\n",
    "    x_sample_nb = len(df_cal)\n",
    "    iter_nb = int(x_sample_nb * 30 / proc_nb)\n",
    "    p = [None, None]\n",
    "    e = [None, None]\n",
    "    p[0] = peq.loc[:, 'p0'].values\n",
    "    p[1] = peq.loc[:, 'p1'].values\n",
    "    e[0] = peq.loc[:, 'e0'].values\n",
    "    e[1] = peq.loc[:, 'e1'].values\n",
    "    q_cal = peq.loc[:, 'q_cal'].values\n",
    "    q = peq.loc[:, 'q'].values\n",
    "    len_peq = len(peq)\n",
    "    q_sim = [np.empty(len_peq * 4), np.empty(len_peq * 4)]\n",
    "    ind = np.array([[0 ,0 ,0 ,0 ,0], [0, 0, 0, 0, 0]], dtype = 'int')\n",
    "    for i in tqdm(range(iter_nb)):\n",
    "        for ws_i in range(2):\n",
    "            for x_i in range(5):\n",
    "                param = 'x' + str(ws_i) + '_' + str(x_i + 1)\n",
    "                this_range = param + '_range'\n",
    "                delta = abs(df_cal.loc[0, this_range] - df_cal.loc[1, this_range]) / 2\n",
    "                this_rand = random.randint(0, x_sample_nb - 2)\n",
    "                df_x.loc[ws_i, 'x' + str(x_i + 1)] = df_cal.loc[this_rand, this_range] + delta\n",
    "                ind[ws_i][x_i]= this_rand\n",
    "            df_x.loc[0, 'x5'] = 0.\n",
    "            this_x = [df_x.loc[ws_i, 'x' + str(x_i + 1)] for x_i in range(4)]\n",
    "            #this_peq = peq.loc[:, ['p' + str(ws_i), 'e' + str(ws_i)]].rename(columns = {'p' + str(ws_i): 'p', 'e' + str(ws_i): 'e'})\n",
    "            q_mod = cmod.gr4h(this_x)\n",
    "            q_sim[ws_i][0 * len_peq:1 * len_peq] = q_mod.run([p[ws_i], e[ws_i]])\n",
    "            q_sim[ws_i][1 * len_peq:2 * len_peq] = q_mod.run([p[ws_i], e[ws_i]])\n",
    "            q_sim[ws_i][2 * len_peq:3 * len_peq] = q_mod.run([p[ws_i], e[ws_i]])\n",
    "            q_sim[ws_i][3 * len_peq:4 * len_peq] = q_mod.run([p[ws_i], e[ws_i]])\n",
    "            q_sim[ws_i] = cmod.delay([df_x.loc[ws_i, 'x5'] + df_x.loc[ws_i, 'x5+']]).run([q_sim[ws_i] * df_x.loc[ws_i, 'weight']])\n",
    "        q_sim2 = q_sim[0][-len_peq:] + q_sim[1][-len_peq:] + q_cal\n",
    "        q_obs = dist_map(q, q_sim2)\n",
    "\n",
    "        ind[0][4] = 0\n",
    "        warmup = 24 * 30\n",
    "        score = cal.nse(q_obs[warmup:], q_sim2[warmup:])\n",
    "        for ws_i in range(2):\n",
    "            for x_i in range(5):\n",
    "                param = 'x' + str(ws_i) + '_' + str(x_i + 1)\n",
    "                if score > df_cal.loc[ind[ws_i][x_i], param + '_score']:\n",
    "                    df_cal.loc[ind[ws_i][x_i], param + '_score'] = score\n",
    "    return df_cal\n",
    "\n",
    "def get_mse(x, peq):\n",
    "    x_range = [\n",
    "        [0., np.inf],\n",
    "        [-np.inf, np.inf],\n",
    "        [0., np.inf],\n",
    "        [0., np.inf],\n",
    "        [0., np.inf],\n",
    "        [-np.inf, np.inf],\n",
    "        [0., np.inf]\n",
    "        ]\n",
    "    # forbidden x values:\n",
    "    for i in range(7):\n",
    "        if x[i] < x_range[i][0]:\n",
    "            return np.inf\n",
    "        if x[i] > x_range[i][1]:\n",
    "            return np.inf\n",
    "    q_mod = mod.gr4h(x[:4])\n",
    "    # warm-up:\n",
    "    q_mod.run(peq)\n",
    "    q_mod.run(peq)\n",
    "    q_mod.run(peq)\n",
    "    q_sim = q_mod.run(peq)\n",
    "    q_obs = dist_map(peq['q'].values, q_sim.values)\n",
    "\n",
    "    warmup = 24 * 30\n",
    "    score = cal.mse(q_obs[warmup:], q_sim.values[warmup:])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_cal = pd.read_pickle('../data/amazon/df_cal.pkl')\n",
    "except:\n",
    "    x_ranges = [[300, 700], [-1, 1], [1200, 2200], [150, 250]]\n",
    "    df_cal = set_cal(x_ranges)\n",
    "    while True:\n",
    "        proc_nb = 3\n",
    "        pool = Pool(processes = proc_nb)\n",
    "        result = pool.starmap(single_cal, [(peq, df_cal.copy()) for proc in range(proc_nb)])\n",
    "        for x_i in range(4):\n",
    "            this_score = 'x' + str(x_i + 1) + '_score'\n",
    "            for this_df in result:\n",
    "                df_cal.loc[:, this_score] = np.where(this_df.loc[:, this_score] > df_cal.loc[:, this_score], this_df.loc[:, this_score], df_cal.loc[:, this_score])\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        # plot parameters:\n",
    "        x_sample_nb = len(df_cal)\n",
    "        plt.close('all')\n",
    "        plt.figure()\n",
    "        for i in range(4):\n",
    "            a = 4 * 100 + 11 + i\n",
    "            plt.subplot(a)\n",
    "            delta = abs(df_cal.loc[0, 'x' + str(i + 1) + '_range'] - df_cal.loc[1, 'x' + str(i + 1) + '_range']) / 2\n",
    "            plt.plot(df_cal.loc[:x_sample_nb - 2, 'x' + str(i + 1) + '_range'] + delta, df_cal.loc[1:, 'x' + str(i + 1) + '_score'])\n",
    "            if not True:\n",
    "                for this_df in result:\n",
    "                    plt.plot(this_df.loc[:x_sample_nb - 2, 'x' + str(i + 1) + '_range'] + delta, this_df.loc[1:, 'x' + str(i + 1) + '_score'])\n",
    "            plt.title('X' + str(i + 1))\n",
    "        plt.show()\n",
    "        # get best parameters:\n",
    "        x = [0] * 4\n",
    "        for x_i in range(4):\n",
    "            this_range = 'x' + str(x_i + 1) + '_range'\n",
    "            this_score = 'x' + str(x_i + 1) + '_score'\n",
    "            delta = abs(df_cal.loc[0, this_range] - df_cal.loc[1, this_range]) / 2\n",
    "            x[x_i] = df_cal.loc[np.argmax(df_cal.loc[:, this_score]), this_range] - delta\n",
    "        # plot simulation with best parameters:\n",
    "        q_mod = mod.gr4h(x[:4])\n",
    "        # warm-up:\n",
    "        q_mod.run(peq)\n",
    "        q_mod.run(peq)\n",
    "        q_mod.run(peq)\n",
    "        q_sim = q_mod.run(peq)\n",
    "        q_obs = dist_map(peq.loc[:, 'q'].values, q_sim.values)\n",
    "        warmup = 24 * 30\n",
    "        score = cal.nse(q_obs[warmup:], q_sim.values[warmup:])\n",
    "        print('X = ' + str(x))\n",
    "        print('NSE = ' + str(score))\n",
    "        peq['q_sim'] = q_sim\n",
    "        peq['q_obs'] = q_obs\n",
    "        #peq[['p', 'e', 'q_sim']].plot()\n",
    "        peq[['q_sim']].plot(color = 'red')\n",
    "        plt.scatter(peq.index, peq['q_obs'].values, color = 'blue')\n",
    "        plt.title('NSE = ' + str(score))\n",
    "        plt.show()\n",
    "        # adjust parameters:\n",
    "        x_ranges = [\n",
    "            [max(0, x[0] - 100), x[0] + 100],\n",
    "            [x[1] - 0.1, x[1] + 0.1],\n",
    "            [max(0, x[2] - 10), x[2] + 10],\n",
    "            [max(0, x[3] - 1), x[3] + 1]\n",
    "            ]\n",
    "        df_cal = set_cal(x_ranges)\n",
    "        df_cal.to_pickle('../data/amazon/df_cal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_x = pd.read_pickle('../data/amazon/df_x.pkl')\n",
    "    peq['q_cal'] = pd.read_pickle('../data/amazon/q_cal.pkl')\n",
    "except:\n",
    "    # we start from the whole basin\n",
    "    df_x = DataFrame()\n",
    "    df_x.loc[0, 'weight'] = 1.\n",
    "    x0 = [354.54545454545456, -0.28282828282828282, 1780.8080808080806, 191.91919191919192, 0]\n",
    "    for x_i in range(5):\n",
    "        df_x.loc[0, 'x' + str(x_i + 1)] = x0[x_i]\n",
    "    head0 = '0'\n",
    "    df_x.loc[0, 'head'] = head0\n",
    "    odr0 = ''\n",
    "    for this_odr in get_odr_startswith(df_ws.index, head0):\n",
    "        odr0 += this_odr + ';'\n",
    "    odr0 = odr0[:-1]\n",
    "    df_x.loc[0, 'odr'] = odr0\n",
    "    df_x.loc[0, 'area'] = get_area(df_ws, get_odr_startswith(df_ws.index, head0))\n",
    "    df_x.loc[0, 'parent'] = -1\n",
    "    df_x.loc[0, 'x5+'] = 0.\n",
    "    this_peq = DataFrame()\n",
    "    this_peq['e'] = get_pet(df_ws, df_imerg, df_pet, get_odr_startswith(df_ws.index, head0))\n",
    "    this_peq['p'] = get_p_imerg(df_ws, df_imerg, ca_gpm, get_odr_startswith(df_ws.index, head0))\n",
    "    q_mod = mod.gr4h(x0[:4])\n",
    "    # warm-up\n",
    "    q_mod.run(peq)\n",
    "    q_mod.run(peq)\n",
    "    q_mod.run(peq)\n",
    "    q_sim = q_mod.run(this_peq)\n",
    "    q_obs = dist_map(peq['q'].values, q_sim.values)\n",
    "    warmup = 24 * 30\n",
    "    score = cal.nse(q_obs[warmup:], q_sim.values[warmup:])\n",
    "    df_x.loc[0, 'nse'] = score\n",
    "    df_x.loc[0, 'split'] = False\n",
    "    df_x.loc[0, 'valid'] = True\n",
    "    peq['q_cal'] = q_sim\n",
    "    peq['q_cal'].to_pickle('../data/amazon/q_cal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#q_obs_keep = []\n",
    "all_done = False\n",
    "while not all_done:\n",
    "    # find the next basin to split\n",
    "    done = False\n",
    "    rows = df_x.iterrows()\n",
    "    ws_i0 = 0\n",
    "    while not done:\n",
    "        this_row = next(rows)\n",
    "        if not this_row[1]['split']:\n",
    "            done = True\n",
    "        else:\n",
    "            ws_i0 += 1\n",
    "        if ws_i0 == len(df_x):\n",
    "            done = True\n",
    "            all_done = True\n",
    "    if not all_done:\n",
    "        odr0 = this_row[1]['odr'].split(';')\n",
    "        if len(odr0) == 1:\n",
    "            # it only consists of one subbasin, cannot split\n",
    "            df_x.loc[ws_i0, 'split'] = True\n",
    "            df_x.loc[ws_i0, 'valid'] = True\n",
    "        else:\n",
    "            # split and get rainfall for each half\n",
    "            x0 = [this_row[1]['x' + str(x_i + 1)] for x_i in range(5)]\n",
    "            area0 = this_row[1]['area']\n",
    "            weight0 = this_row[1]['weight']\n",
    "            head0 = this_row[1]['head']\n",
    "            area = [None, None]\n",
    "            odr = [None, None]\n",
    "            head = [head0, None]\n",
    "            diff_area = np.inf\n",
    "            for this_odr in tqdm(odr0):\n",
    "                odr_1 = intersect_odr(get_odr_startswith(df_ws.index, this_odr), odr0)\n",
    "                this_area = get_area(df_ws, odr_1)\n",
    "                diff = abs(area0 / 2 - this_area)\n",
    "                if diff < diff_area:\n",
    "                    diff_area = diff\n",
    "                    head[1] = this_odr\n",
    "                    area[1] = this_area\n",
    "                    odr[1] = odr_1\n",
    "            area[0] = area0 - area[1]\n",
    "            odr[0] = substract_odr(odr0, odr[1])\n",
    "            show_ws(odr[0])\n",
    "            show_ws(odr[1])\n",
    "            peq['e0'] = get_pet(df_ws, df_imerg, df_pet, odr[0])\n",
    "            peq['e1'] = get_pet(df_ws, df_imerg, df_pet, odr[1])\n",
    "            peq['p0'] = get_p_imerg(df_ws, df_imerg, ca_gpm, odr[0])\n",
    "            peq['p1'] = get_p_imerg(df_ws, df_imerg, ca_gpm, odr[1])\n",
    "            # remove the part of the catchment we are going to split:\n",
    "            this_x = [df_x.loc[ws_i0, 'x' + str(x_i + 1)] for x_i in range(4)]\n",
    "            this_peq = DataFrame()\n",
    "            this_peq['e'] = get_pet(df_ws, df_imerg, df_pet, df_x.loc[ws_i0, 'odr'].split(';'))\n",
    "            this_peq['p'] = get_p_imerg(df_ws, df_imerg, ca_gpm, df_x.loc[ws_i0, 'odr'].split(';'))\n",
    "            q_mod = cmod.gr4h(this_x)\n",
    "            q_sim = q_mod.run([this_peq.p.values, this_peq.e.values])\n",
    "            q_sim = np.append(q_sim, q_mod.run([this_peq.p.values, this_peq.e.values]))\n",
    "            q_sim = np.append(q_sim, q_mod.run([this_peq.p.values, this_peq.e.values]))\n",
    "            q_sim = np.append(q_sim, q_mod.run([this_peq.p.values, this_peq.e.values]))\n",
    "            q_sim = q_sim * df_x.loc[ws_i0, 'weight']\n",
    "            q_sim = cmod.delay([df_x.loc[ws_i0, 'x5+']]).run([q_sim])[-len(this_peq):]\n",
    "            q_sim = Series(data = q_sim, index = this_peq.index)\n",
    "            peq['q_cal'] = peq['q_cal'] - q_sim\n",
    "            # prepare calibration of each half\n",
    "            x_sample_nb = 100\n",
    "            xlen = len(df_x)\n",
    "            retry = True\n",
    "            while retry:\n",
    "                df_cal = DataFrame()\n",
    "                for ws_i in range(2):\n",
    "                    for x_i in range(5):\n",
    "                        df_x.loc[xlen + ws_i, 'x' + str(x_i + 1)] = x0[x_i]\n",
    "                    df_x.loc[xlen + ws_i, 'weight'] = area[ws_i] / area0 * weight0\n",
    "                    df_x.loc[xlen + ws_i, 'area'] = area[ws_i]\n",
    "                    df_x.loc[xlen + ws_i, 'head'] = head[ws_i]\n",
    "                    df_x.loc[xlen + ws_i, 'parent'] = ws_i0\n",
    "                    odr_str = ''\n",
    "                    for this_odr in odr[ws_i]:\n",
    "                        odr_str += this_odr + ';'\n",
    "                    odr_str = odr_str[:-1]\n",
    "                    df_x.loc[xlen + ws_i, 'odr'] = odr_str\n",
    "                    df_x.loc[xlen + ws_i, 'x5'] = 0\n",
    "                    # before calibration, x5+ doesn't include x5\n",
    "                    df_x.loc[xlen + ws_i, 'x5+'] = df_x.loc[ws_i0, 'x5+']\n",
    "                    df_x.loc[xlen + ws_i, 'split'] = False\n",
    "                    df_x.loc[xlen + ws_i, 'valid'] = False\n",
    "                    this_x = [df_x.loc[xlen + ws_i, 'x' + str(x_i + 1)] for x_i in range(5)]\n",
    "                    for x_i in range(5):\n",
    "                        if x_i == 0:\n",
    "                            a = max(0, this_x[x_i] - 1000)\n",
    "                            b = this_x[x_i] + 1000\n",
    "                        elif x_i == 1:\n",
    "                            a = this_x[x_i] - 0.5\n",
    "                            b = this_x[x_i] + 0.5\n",
    "                        elif x_i == 2:\n",
    "                            a = max(0, this_x[x_i] - 1000)\n",
    "                            b = this_x[x_i] + 1000\n",
    "                        elif x_i == 3:\n",
    "                            a = max(0, this_x[x_i] - 100)\n",
    "                            b = this_x[x_i] + 100\n",
    "                        elif x_i == 4:\n",
    "                            x5_max = np.inf\n",
    "                            for i, this_i in enumerate(df_x.index):\n",
    "                                if df_x.loc[this_i, 'head'].startswith(df_x.loc[xlen + ws_i, 'head']) and df_x.loc[this_i, 'valid'] and i != xlen + ws_i:\n",
    "                                    if df_x.loc[this_i, 'x5+'] < x5_max:\n",
    "                                        x5_max = df_x.loc[this_i, 'x5+']\n",
    "                            if np.isinf(x5_max):\n",
    "                                b = 1000\n",
    "                            else:\n",
    "                                b = x5_max - df_x.loc[ws_i0, 'x5+']\n",
    "                            a = 0\n",
    "                        param = 'x' + str(ws_i) + '_' + str(x_i + 1)\n",
    "                        df_cal[param + '_range'] = np.linspace(a, b, x_sample_nb)\n",
    "                        df_cal[param + '_score'] = -np.inf\n",
    "                if (df_x.loc[xlen, 'head'].startswith(df_x.loc[xlen + 1, 'head']) or df_x.loc[xlen + 1, 'head'].startswith(df_x.loc[xlen, 'head'])) and not np.isinf(x5_max):\n",
    "                    df_cal['x0_5_range'] = np.linspace(0, (x5_max - df_x.loc[ws_i0, 'x5+']) / 2, x_sample_nb)\n",
    "                    df_cal['x1_5_range'] = np.linspace(0, (x5_max - df_x.loc[ws_i0, 'x5+']) / 2, x_sample_nb)\n",
    "                # perform calibration\n",
    "                proc_nb = 3\n",
    "                if proc_nb == 1:\n",
    "                    df_cal = dual_cal(peq, df_cal, df_x.loc[xlen:].reset_index(drop = True), proc_nb)\n",
    "                else:\n",
    "                    pool = Pool(processes = proc_nb)\n",
    "                    result = pool.starmap(dual_cal, [(peq, df_cal.copy(), df_x.loc[xlen:].reset_index(drop = True).copy(), proc_nb) for proc in range(proc_nb)])\n",
    "                    for ws_i in range(2):\n",
    "                        for x_i in range(5):\n",
    "                            this_score = 'x' + str(ws_i) + '_' + str(x_i + 1) + '_score'\n",
    "                            for this_df in result:\n",
    "                                df_cal.loc[:, this_score] = np.where(this_df.loc[:, this_score] > df_cal.loc[:, this_score], this_df.loc[:, this_score], df_cal.loc[:, this_score])\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "                for ws_i in range(2):\n",
    "                    for x_i in range(5):\n",
    "                        param = 'x' + str(ws_i) + '_' + str(x_i + 1)\n",
    "                        max_i = np.argmax(df_cal.loc[:, param + '_score'])\n",
    "                        delta = abs(df_cal.loc[0, param + '_range'] - df_cal.loc[1, param + '_range']) / 2\n",
    "                        df_x.loc[xlen + ws_i, 'x' + str(x_i + 1)] = df_cal.loc[max_i, param + '_range'] + delta\n",
    "                df_x.loc[xlen, 'x5'] = 0.\n",
    "                for ws_i in range(2):\n",
    "                    df_x.loc[xlen + ws_i, 'valid'] = True\n",
    "                    # after calibration, x5+ includes x5\n",
    "                    df_x.loc[xlen + ws_i, 'x5+'] = df_x.loc[xlen + ws_i, 'x5'] + df_x.loc[ws_i0, 'x5+']\n",
    "                fig = plt.figure()\n",
    "                ax = fig.add_subplot(111)\n",
    "                for ws_i in df_x.index[xlen:]:\n",
    "                    this_x = [df_x.loc[ws_i, 'x' + str(x_i + 1)] for x_i in range(4)]\n",
    "                    this_peq = DataFrame()\n",
    "                    this_peq['e'] = get_pet(df_ws, df_imerg, df_pet, df_x.loc[ws_i, 'odr'].split(';'))\n",
    "                    this_peq['p'] = get_p_imerg(df_ws, df_imerg, ca_gpm, df_x.loc[ws_i, 'odr'].split(';'))\n",
    "                    q_mod = cmod.gr4h(this_x)\n",
    "                    q_sim = q_mod.run([this_peq.p.values, this_peq.e.values])\n",
    "                    q_sim = np.append(q_sim, q_mod.run([this_peq.p.values, this_peq.e.values]))\n",
    "                    q_sim = np.append(q_sim, q_mod.run([this_peq.p.values, this_peq.e.values]))\n",
    "                    q_sim = np.append(q_sim, q_mod.run([this_peq.p.values, this_peq.e.values]))\n",
    "                    q_sim = cmod.delay([df_x.loc[ws_i, 'x5+']]).run([q_sim])[-len(this_peq):]\n",
    "                    q_sim = Series(data = q_sim, index = this_peq.index)\n",
    "                    peq['q' + str(ws_i - xlen)] = q_sim\n",
    "                    q_sim = q_sim * df_x.loc[ws_i, 'weight']\n",
    "                    peq['q_cal'] = peq['q_cal'] + q_sim\n",
    "                q_obs = dist_map(peq['q'].values, peq['q_cal'].values)\n",
    "                #q_obs_keep.append(Series(q_obs, index = peq.index).interpolate())\n",
    "                peq['q_obs'] = q_obs\n",
    "                warmup = 24 * 30\n",
    "                score = cal.nse(peq['q_obs'].values[warmup:], peq['q_cal'].values[warmup:])\n",
    "                for ws_i in range(2):\n",
    "                    df_x.loc[xlen + ws_i, 'nse'] = score\n",
    "                if True:#score > df_x.loc[ws_i0, 'nse'] - 0.01:\n",
    "                    retry = False\n",
    "                else:\n",
    "                    plt.close('all')\n",
    "                    print(df_x.loc[xlen:])\n",
    "            df_x.loc[ws_i0, 'split'] = True\n",
    "            df_x.loc[ws_i0, 'valid'] = False\n",
    "            \n",
    "            peq['q_cal'].plot(ax = ax, color = 'green')\n",
    "            ax.scatter(peq['q_obs'].index, peq['q_obs'].values, color = 'blue')\n",
    "            ax.set_title('NSE = ' + str(score))\n",
    "            plt.show()\n",
    "            \n",
    "            #plt.close('all')\n",
    "            #for this_q in q_obs_keep:\n",
    "            #    this_q.plot(color = 'grey')\n",
    "            #plt.show()\n",
    "            \n",
    "            if True:\n",
    "                for ws_i in range(2):\n",
    "                    plt.close('all')\n",
    "                    plt.figure()\n",
    "                    for x_i in range(5):\n",
    "                        a = 5 * 100 + 11 + x_i\n",
    "                        param = 'x' + str(ws_i) + '_' + str(x_i + 1)\n",
    "                        plt.subplot(a)\n",
    "                        delta = abs(df_cal.loc[0, param + '_range'] - df_cal.loc[1, param + '_range']) / 2\n",
    "                        plt.plot(df_cal.loc[:x_sample_nb - 2, param + '_range'] + delta, df_cal.loc[1:, param + '_score'])\n",
    "                        if not True:\n",
    "                            for this_df in result:\n",
    "                                plt.plot(this_df.loc[:x_sample_nb - 2, 'x' + param + '_range'] + delta, this_df.loc[1:, 'x' + param + '_score'])\n",
    "                        plt.title('X' + str(x_i + 1))\n",
    "                    plt.show()\n",
    "\n",
    "            df_x.to_pickle('../data/amazon/df_x.pkl')\n",
    "            peq['q_cal'].to_pickle('../data/amazon/q_cal.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
